# ğŸ” MiniSearch

A lightning-fast Wikipedia search engine built from scratch with Python, featuring BM25 ranking, AI-powered summaries, and support for phrase queries and boolean operators.

![Python](https://img.shields.io/badge/python-3.13-blue.svg)
![Flask](https://img.shields.io/badge/flask-3.1-green.svg)
![License](https://img.shields.io/badge/license-MIT-orange.svg)

## âœ¨ Features

- **ğŸš€ Fast BM25 Ranking**: Industry-standard probabilistic ranking algorithm for relevant search results
- **ğŸ¤– AI Summaries**: Get instant overviews of search results powered by Groq's Llama 3.3 70B
- **ğŸ“ Advanced Query Syntax**:
  - Simple multi-word queries: `neural networks`
  - Phrase search: `"machine learning"`
  - Boolean operators: `python AND (learning OR neural) NOT robotics`
- **ğŸ“š 10,000 Wikipedia Articles**: Pre-indexed and ready to search
- **âš¡ Inverted Index**: Sub-second query response times
- **ğŸ¨ Clean UI**: Modern, responsive interface with real-time results

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚  Static HTML/CSS/JS
â”‚   (index.html)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ HTTP API
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flask App     â”‚  Search endpoint + routing
â”‚   (app.py)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query Engine   â”‚  BM25 scoring, query parsing
â”‚(query_engine.py)â”‚  AI summary generation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Inverted Index  â”‚  Term â†’ Doc mappings
â”‚  (index.json)   â”‚  TF-IDF, positions
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

- **Backend**: Python 3.13, Flask, Gunicorn
- **AI**: Groq API (Llama 3.3 70B)
- **Search**: Custom BM25 implementation with Porter Stemmer
- **Data**: 10,000 Wikipedia articles (crawled via Wikipedia API)
- **Deployment**: Railway (or any cloud platform)

## ğŸ“¦ Installation

### Prerequisites

- Python 3.13+
- pip
- (Optional) Groq API key for AI summaries

### Local Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/minisearch.git
   cd minisearch
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables** (optional, for AI summaries)
   ```bash
   echo "GROQ_API_KEY=your_groq_api_key_here" > .env
   ```
   Get your free API key at [console.groq.com](https://console.groq.com)

4. **Run the application**
   ```bash
   python app.py
   ```

5. **Open in browser**
   ```
   http://localhost:5000
   ```

## ğŸš€ Deployment

### Deploy to Railway

1. **Push to GitHub**
   ```bash
   git init
   git add .
   git commit -m "Initial commit"
   git remote add origin your-repo-url
   git push -u origin main
   ```

2. **Connect to Railway**
   - Go to [railway.app](https://railway.app)
   - Create new project â†’ Deploy from GitHub
   - Select your repository
   - Add environment variable: `GROQ_API_KEY` (if using AI summaries)

3. **Done!** Railway will auto-deploy your app

### Deploy to Other Platforms

The app works on any platform that supports Python web apps:
- **Render**: Add `Procfile` and deploy
- **Heroku**: Standard Python deployment
- **AWS/GCP**: Use Elastic Beanstalk or App Engine

## ğŸ“– Usage

### Simple Search
```
neural networks
```
Returns all documents containing both "neural" and "networks"

### Phrase Search
```
"machine learning"
```
Finds exact phrase matches where words appear consecutively

### Boolean Queries
```
python AND (learning OR neural) NOT robotics
```
Supports AND, OR, NOT operators with parentheses for grouping

### AI Summaries
AI-powered overviews are automatically generated for every search when `GROQ_API_KEY` is configured. Disable by adding `?summary=false` to the search URL.

## ğŸ—‚ï¸ Project Structure

```
minisearch/
â”œâ”€â”€ app.py                 # Flask application entry point
â”œâ”€â”€ query_engine.py        # Search engine core (BM25, AI summaries)
â”œâ”€â”€ indexer.py            # Inverted index builder + Porter stemmer
â”œâ”€â”€ crawler.py            # Wikipedia data crawler
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ Procfile             # Deployment configuration
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html       # Frontend UI
â”œâ”€â”€ crawled_data.json    # Raw Wikipedia articles (10,000 pages)
â””â”€â”€ index.json           # Inverted index (generated from crawler)
```

## ğŸ”§ How It Works

### 1. Data Collection (`crawler.py`)
- Crawls Wikipedia API starting from seed topics
- Fetches article text and outbound links
- Saves 10,000 articles to `crawled_data.json`

### 2. Indexing (`indexer.py`)
- Tokenizes text (lowercase, remove stopwords, stem)
- Builds inverted index: `term â†’ {doc_freq, postings}`
- Stores term frequencies and positions for phrase search
- Saves to `index.json`

### 3. Query Processing (`query_engine.py`)
- Parses user query (simple/phrase/boolean)
- Scores documents using BM25 algorithm
- Generates snippets with highlighted terms
- Optionally creates AI summary via Groq API

### 4. Serving Results (`app.py`)
- Flask endpoint `/search?q=...&summary=true`
- Returns JSON with ranked results + AI overview
- Frontend renders results in real-time

## ğŸ§® BM25 Algorithm

MiniSearch uses the BM25 ranking function:

```
score(D,Q) = Î£ IDF(qáµ¢) Â· (f(qáµ¢,D) Â· (kâ‚ + 1)) / (f(qáµ¢,D) + kâ‚ Â· (1 - b + b Â· |D| / avgdl))
```

Where:
- `IDF(qáµ¢)` = Inverse document frequency of term qáµ¢
- `f(qáµ¢,D)` = Frequency of qáµ¢ in document D
- `|D|` = Length of document D
- `avgdl` = Average document length
- `kâ‚` = 1.5 (term frequency saturation)
- `b` = 0.75 (length normalization)

## ğŸ¤– AI Summaries

Powered by **Groq's Llama 3.3 70B Versatile** model:
- Synthesizes top 3 search results
- Generates concise 150-word overviews
- Sub-second response times
- Falls back gracefully if API unavailable

## ğŸ“Š Performance

- **Index Size**: 10,000 documents, 45,000+ unique terms
- **Query Time**: ~50-200ms (excluding AI summary)
- **AI Summary Time**: ~500-1000ms (via Groq)
- **Memory Usage**: ~150MB (index loaded in RAM)

## ğŸ” Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `GROQ_API_KEY` | No | API key for AI summaries (get free at console.groq.com) |
| `PORT` | No | Server port (default: 5000, auto-assigned on Railway) |

## ğŸ§ª Testing

Run the search engine REPL for interactive testing:

```bash
python query_engine.py
```

Example session:
```
ğŸ” Search: artificial intelligence
  #1  [12.34]  Artificial Intelligence
      https://en.wikipedia.org/wiki/Artificial_intelligence
      ...AI is the simulation of human **intelligence** processes...
```

## ğŸ›£ï¸ Roadmap

- [ ] Add autocomplete suggestions
- [ ] Implement query spell-checking
- [ ] Support for filters (date, category)
- [ ] User search history
- [ ] PDF export of results
- [ ] Multi-language support

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Wikipedia** for providing the data via their API
- **Groq** for fast AI inference
- **Flask** for the lightweight web framework
- **Porter Stemmer** algorithm for text normalization

